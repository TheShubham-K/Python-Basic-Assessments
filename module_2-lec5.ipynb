{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tesseract and Photographs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets try a new example and bring together some of the things we have learned.\n",
    "# Here's an image of a storefront, lets load it and try and get the name of the\n",
    "# store out of the image\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "# Lets read in the storefront image I've loaded into the course and display it\n",
    "image=Image.open('readonly/storefront.jpg')\n",
    "display(image)\n",
    "# Finally, lets try and run tesseract on that image and see what the results are\n",
    "pytesseract.image_to_string(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We see at the very bottom there is just an empty string. Tesseract is unable to take\n",
    "# this image and pull out the name. But we learned how to crop the images in the\n",
    "# last set of lectures, so lets try and help Tesseract by cropping out certain pieces.\n",
    "#\n",
    "# First, lets set the bounding box. In this image the store name is in a box\n",
    "# bounded by (315, 170, 700, 270)\n",
    "bounding_box=(315, 170, 700, 270)\n",
    "\n",
    "# Now lets crop the image\n",
    "title_image=image.crop(bounding_box)\n",
    "\n",
    "# Now lets display it and pull out the text\n",
    "display(title_image)\n",
    "pytesseract.image_to_string(title_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Great, we see how with a bit of a problem reduction we can make that work. So now we have\n",
    "# been able to take an image, preprocess it where we expect to see text, and turn that text\n",
    "# into a string that python can understand.\n",
    "#\n",
    "# If you look back up at the image though, you'll see there is a small sign inside of the\n",
    "# shop that also has the shop name on it. I wonder if we're able to recognize the text on \n",
    "# that sign? Let's give it a try.\n",
    "#\n",
    "# First, we need to determine a bounding box for that sign. I'm going to show you a short-cut\n",
    "# to make this easier in an optional video in this module, but for now lets just use the bounding\n",
    "# box I decided on\n",
    "bounding_box=(900, 420, 940, 445)\n",
    "\n",
    "# Now, lets crop the image\n",
    "little_sign=image.crop((900, 420, 940, 445))\n",
    "display(little_sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All right, that is a little sign! OCR works better with higher resolution images, so\n",
    "# lets increase the size of this image by using the pillow resize() function\n",
    "# Lets set the width and height equal to ten times the size it is now in a (w,h) tuple\n",
    "new_size=(little_sign.width*10,little_sign.height*10)\n",
    "\n",
    "# Now lets check the docs for resize()\n",
    "help(little_sign.resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We can see that there are a number of different filters for resizing the image. The\n",
    "# default is Image.NEAREST. Lets see what that looks like\n",
    "display(little_sign.resize( new_size, Image.NEAREST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I think we should be able to find something better. I can read it, but it looks\n",
    "# really pixelated. Lets see what all the different resize options look like\n",
    "options=[Image.NEAREST, Image.BOX, Image.BILINEAR, Image.HAMMING, Image.BICUBIC, Image.LANCZOS]\n",
    "for option in options:\n",
    "    # lets print the option name\n",
    "    print(option)\n",
    "    # lets display what this option looks like on our little sign\n",
    "    display(little_sign.resize( new_size, option))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From this we can notice two things. First, when we print out one of the resampling\n",
    "# values it actually just prints an integer! This is really common: that the\n",
    "# API developer writes a property, such as Image.BICUBIC, and then assigns it to an\n",
    "# integer value to pass it around. Some languages use enumerations of values, which is\n",
    "# common in say, Java, but in python this is a pretty normal way of doing things.\n",
    "# The second thing we learned is that there are a number of different algorithms for\n",
    "# image resampling. In this case, the Image.LANCZOS and Image.BICUBIC filters do a good\n",
    "# job. Lets see if we are able to recognize the text off of this resized image\n",
    "\n",
    "# First lets resize to the larger size\n",
    "bigger_sign=little_sign.resize(new_size, Image.BICUBIC)\n",
    "# Lets print out the text\n",
    "pytesseract.image_to_string(bigger_sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Well, no text there. Lets try and binarize this. First, let me just bring in the\n",
    "# binarization code we did earlier\n",
    "def binarize(image_to_transform, threshold):\n",
    "    output_image=image_to_transform.convert(\"L\")\n",
    "    for x in range(output_image.width):\n",
    "        for y in range(output_image.height):\n",
    "            if output_image.getpixel((x,y))< threshold:\n",
    "                output_image.putpixel( (x,y), 0 )\n",
    "            else:\n",
    "                output_image.putpixel( (x,y), 255 )\n",
    "    return output_image\n",
    "\n",
    "# Now, lets apply binarizations with, say, a threshold of 190, and try and display that\n",
    "# as well as do the OCR work\n",
    "binarized_bigger_sign=binarize(bigger_sign, 190)\n",
    "display(binarized_bigger_sign)\n",
    "pytesseract.image_to_string(binarized_bigger_sign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ok, that text is pretty useless. How should we pick the best binarization\n",
    "# to use? Well, there are some methods, but lets just try something very simple to\n",
    "# show how well this can work. We have an english word we are trying to detect, \"FOSSIL\".\n",
    "# If we tried all binarizations, from 0 through 255, and looked to see if there were\n",
    "# any english words in that list, this might be one way. So lets see if we can\n",
    "# write a routine to do this.\n",
    "#\n",
    "# First, lets load a list of english words into a list. I put a copy in the readonly\n",
    "# directory for you to work with\n",
    "eng_dict=[]\n",
    "with open (\"readonly/words_alpha.txt\", \"r\") as f:\n",
    "    data=f.read()\n",
    "    # now we want to split this into a list based on the new line characters\n",
    "    eng_dict=data.split(\"\\n\")\n",
    "\n",
    "# Now lets iterate through all possible thresholds and look for an english word, printing\n",
    "# it out if it exists\n",
    "for i in range(150,170):\n",
    "    # lets binarize and convert this to s tring values\n",
    "    strng=pytesseract.image_to_string(binarize(bigger_sign,i))\n",
    "    # We want to remove non alphabetical characters, like ([%$]) from the text, here's\n",
    "    # a short method to do that\n",
    "    # first, lets convert our string to lower case only\n",
    "    strng=strng.lower()\n",
    "    # then lets import the string package - it has a nice list of lower case letters\n",
    "    import string\n",
    "    # now lets iterate over our string looking at it character by character, putting it in\n",
    "    # the comaprison text\n",
    "    comparison=''\n",
    "    for character in strng:\n",
    "        if character in string.ascii_lowercase:\n",
    "            comparison=comparison+character\n",
    "    # finally, lets search for comparison in the dictionary file\n",
    "    if comparison in eng_dict:\n",
    "        # and print it if we find it\n",
    "        print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Well, not perfect, but we see fossil there among other values which are in the dictionary.\n",
    "# This is not a bad way to clean up OCR data. It can useful to use a language or domain specific \n",
    "# dictionary in practice, especially if you are generating a search engine for specialized language\n",
    "# such as a medical knowledge base or locations. And if you scroll up and look at the data\n",
    "# we were working with - this small little wall hanging on the inside of the store - it's not\n",
    "# so bad.\n",
    "#\n",
    "# At this point you've now learned how to manipulate images and convert them into text. In the\n",
    "# next module in this course we're going to dig deeper further into a computer vision library\n",
    "# which allows us to detect faces among other things. Then, on to the culminating project!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Module 2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
