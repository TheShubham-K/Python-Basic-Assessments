{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Jupyter Widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ipywebrtc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7901539bb36f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# First, lets import from this library two different classes which we'll use in a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# demo, one for the camera and one for images.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mipywebrtc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCameraStream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageRecorder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# Then lets take a look at the camera stream object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mhelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCameraStream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipywebrtc'"
     ]
    }
   ],
   "source": [
    "# One of the nice things about using the Jupyter notebook systems is that there is a\n",
    "# rich set of contributed plugins that seek to extend this system. In this lecture I\n",
    "# want to introduce you to one such plugin, call ipy web rtc. Webrtc is a fairly new\n",
    "# protocol for real time communication on the web. Yup, I'm talking about chatting.\n",
    "# The widget brings this to the Jupyter notebook system. Lets take a look.\n",
    "#\n",
    "# First, lets import from this library two different classes which we'll use in a\n",
    "# demo, one for the camera and one for images.\n",
    "from ipywebrtc import CameraStream, ImageRecorder\n",
    "# Then lets take a look at the camera stream object\n",
    "help(CameraStream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We see from the docs that it's east to get a camera facing the user, and we can have\n",
    "# the audio on or off. We don't need audio for this demo, so lets create a new camera\n",
    "# instance\n",
    "camera = CameraStream.facing_user(audio=False)\n",
    "# The next object we want to look at is the ImageRecorder\n",
    "help(ImageRecorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The image recorder lets us actually grab images from the camera stream. There are features\n",
    "# for downloading and using the image as well. We see that the default format is a png file.\n",
    "# Lets hook up the ImageRecorder to our stream\n",
    "image_recorder = ImageRecorder(stream=camera)\n",
    "# Now, the docs are a little unclear how to use this within Jupyter, but if we call the\n",
    "# download() function it will actually store the results of the camera which is hooked up\n",
    "# in image_recorder.image. Lets try it out\n",
    "# First, lets tell the recorder to start capturing data\n",
    "image_recorder.recording=True\n",
    "# Now lets download the image\n",
    "image_recorder.download()\n",
    "# Then lets inspect the type of the image\n",
    "type(image_recorder.image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ok, the object that it stores is an ipywidgets.widgets.widget_media.Image. How do we do\n",
    "# something useful with this? Well, an inspection of the object shows that there is a handy\n",
    "# value field which actually holds the bytes behind the image. And we know how to display\n",
    "# those.\n",
    "# Lets import PIL Image\n",
    "import PIL.Image\n",
    "# And lets import io\n",
    "import io\n",
    "# And now lets create a PIL image from the bytes\n",
    "img = PIL.Image.open(io.BytesIO(image_recorder.image.value))\n",
    "# And render it to the screen\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Great, you see a picture! Hopefully you are following along in one of the notebooks\n",
    "# and have been able to try this out for yourself!\n",
    "#\n",
    "# What can you do with this? This is a great way to get started with a bit of computer vision.\n",
    "# You already know how to identify a face in the webcam picture, or try and capture text\n",
    "# from within the picture. With OpenCV there are any number of other things you can do, simply\n",
    "# with a webcam, the Jupyter notebooks, and python!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
